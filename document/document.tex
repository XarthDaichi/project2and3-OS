\documentclass[12pt, article, natbib]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{fancyhdr}
\usepackage{mathtools}
\usepackage{tikz}

\pagestyle{fancy}
\fancyhf{Universidad Nacional de Costa Rica}
\rhead{\thepage}
\lhead{Proyecto \# 1}
\rfoot{EIF-212 Sistemas Operativos}
\lfoot{I-2023}

\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\makeatletter
\renewcommand*\l@section{\@dottedtocline{1}{1.5em}{2.3em}}
\makeatother
\begin{document}

\begin{titlepage}
	\includegraphics[width=0.2\textwidth]{./logo-UNA blanco.png}      
   	\begin{changemargin}{4.5cm}{0cm}
       	\textbf{\Huge Compresor distribuido y descompresor (secuencial)}

       	\vspace{0.2cm}
       	\LARGE Proyecto \# 2
            
       	\vspace{3cm}
		\Large
       	Jorge Durán Campos \\ 
       	Luis Antonio Montes de Oca Ruiz \\ 
       	Diego Quirós Artiñano \\ 

       	\vspace{3cm}
       
		EIF-212 Sistemas Operativos \\
       	Profesor Eddy Ramirez Jiménez \\
		       	
       	\vspace{3cm}
       	\today
	\end{changemargin}
\end{titlepage}

\onecolumn
% Índices
\pagenumbering{roman}
    % Contenido
    \renewcommand{\contentsname}{\large Índice \\ \hrulefill}
\tableofcontents
\setcounter{tocdepth}{2}
\newpage
%     Figuras
%  \renewcommand{\listfigurename}{\large Índice de fíguras \\ \hrulefill}
%  \listoffigures
%  \newpage
     % Tablas
%  \renewcommand{\listtablename}{\large Índice de tablas \\ \hrulefill}
%  \listoftables
%  \newpage
% Cuerpo
\pagenumbering{arabic}
\section{Resumen Ejecutivo}
El presente proyecto trata sobre un problema de manejo de hilos, estos se van a dividir en dos categorías, productores y consumidores. Los productores van a leer un archivo byte por byte y los colocan en un buffer, los consumidores toman los datos del buffer, igual byte por byte, y cuenta las repeticiones de cada byte, colocando la cantidad de repeticiones en un arreglo, en una posición i, donde i representa el byte, es decir si el byte 254 se repite 3 veces, en la posición del 254 del arreglo va a estar el entero 3. Para poder solucionar el problema planteado se implementaron varios mecanismos como los MUTEX (mutual exclusion) \cite{whiletruethendream_2020_mutex}, wait conditions, y threads ya que es el punto esencial de este proyecto.\cite{threadsInCEducative} \cite{codevault_2020_short} \cite{portfoliocourses_2022_introduction} \cite{whiletruethendream_2018_programar}\\

Esta solución se implementa por medio de distintos métodos, uno para leer el archivo deseado byte por byte por cada hilo productor, otro para que los hilos consumidores tomen los bytes de los productores y se coloque la cantidad de repeticiones en el arreglo, como se mencionó anteriormente, y el uso del algoritmo de ordenamiento merge sort, ya que, al ser 256 posiciones por ordenar, se consideró que este era la mejor opción. Finalmente, cada uno de estos métodos se llaman dentro del main, junto con las verificaciones necesarias y la ejecución y unión de los hilos productores y consumidores, y se termina con la impresión en pantalla del resultado de las repeticiones por cada byte. Estos metodos se describen a continuacion\\

El primer metodo es el metodo auxiliar de merge sort, llamado merge() este implementa toda la logica de ordenamiento del merge sort, y luego está el metodo mergesort() que se encarga de unir el resultado en un arreglo auxiliar, utilizando como guia el arreglo de solucion que se genera en el metodo adding\_to\_array(). Despues se crea el metodo reading\_file() el cual es la tarea de los hilos lectores, aqui se hace uso del archivo que se indica al ejecutar el programa y se hace la lectura byte por byte, existen tambien varias verificaciones como si se llegó a final de archivo, se hace uso de bloqueos al buffer de lectura por medio de MUTEX, de flags para saber si se llegó a final de archivo, y tambien de broadcasts para indicar que se terminó la lectura. Por último se encuentra el metodo adding\_to\_array() el cual es el que se les asigna a los hilos consumidores, este se va a encargar de tomar cada byte introducido en el buffer por los productores, identificar cuantas repeticiones hay de un mimso byte y colocarlo en un arreglo de solucion, en este metodo tambien se manejan verificaciones como que si la posicion de los consumidores es mayor o igual a la posicion de los productores en el archivo, se usa tambien bloqueos pero esta vez en el arreglo de solucion utilizando MUTEX, existen condiciones de espera como la mencionada anteriormente y por ultimo igual se hace un boradcast de que los hilos consumidores terminaron su tarea de procesar todo el buffer. Finalmente, dentro del main, como se mencionó anteriormente, existen verificaciones para la cantidad de hilos productores y consumidores, para la direccion del archivo y la correcta apertura del mismo, si se realizó correctamente la creacion de los hilos y si estos se unieron correctamente al hilo principal, se realiza el ordenamiento merge sort y se presenta en pantalla el resultado de todo el programa, ordenando cada byte de mayor a menor de acuerdo a su cantidad de repeticiones en el archivo indicado, al final se destruyen los MUTEX y condiciones declaradas al inicio del programa\\

Finalmente, se realizaron varias pruebas de lectura con 7 archivos de distintos tamaños y de distintos tipos, con cuatro distintos casos de prueba, misma cantidad de hilos productores y consumidores, 10 productores 1 consumidor, 1 productor 10 consumidores, y 5 productores 8 consumidores. De estas se obtuvo la conclusión que el mejor caso es cuanto existe una cantidad igual de ambos tipos de hilos, y la peor cuando existen más lectores que consumidores, ya que estos consumidores van a quedar esperando hasta que el único productor haga la lectura de un byte y esto genera un proceso de “back and forth” donde los consumidores deben esperar al productor continuamente.\\

\newpage
\twocolumn
\section{Introducción}
Este documento tiene como objetivo servir como documentación del segundo proyecto del curso de sistemas operativos. Este consta de un resumen ejecutivo en el cual se explica brevemente el proyecto junto a su solución y resultados, un marco teórico donde se describen aspectos relacionados al proyecto, como el leguaje, las bibliotecas y una demostración del algoritmo de Huffman, una descripción de la solución implementada al problema planteado en el enunciado del proyecto, los resultados de las pruebas de la solución, las conclusiones donde se analizan los resultados y el proyecto en general, y por último se presentan los aprendizajes obtenidos al realizar el proyecto. Además, el proyecto se basa en realizar un compresor distribuido de cualquier tipo de archivo, sea un video, un texto o demás, este archivo es leído de manera binaria usando hilos que van byte por byte del archivo, este va a ir contando la cantidad de repeticiones de un byte especifico de los 256 bytes que existen y así asignarles una ruta compuesta de unos y ceros, usando el algoritmo de Huffmann. Se entregarán tres archivos distintos, uno siendo los datos comprimidos, otro con los datos del árbol y otro que contiene la tabla de códigos de Huffmann creados al comprimir el archivo.

\section{Marco teórico}
El lenguaje utilizado en este proyecto es C, el cual se creó a principios de los años 1970 por Dennis M. Ritchie en Bell Laboratories. Este fue diseñado como un lenguaje minimalista para la creación de sistemas operativos para minicomputadoras, las cuales eran computadoras más baratas y menos potentes que una supercomputadora, pero más caras y potentes que una computadora personal. El principal motivo fue el deseo de migrar el kernel del sistema pronto a ser terminado, UNIX, a un lenguaje de alto nivel, teniendo las mismas funciones, pero con menos líneas de código. C se basó en CPL, o Combined Programming Language, por sus siglas en inglés, el cual a su vez sirvió de base para el lenguaje B. De este, Ritchie reescribió varias funciones de CPL para crear C y después reescribió UNIX en este nuevo lenguaje.\cite{encyclopdiabritannica_2022_c} \cite{munoz_after}\\

Desde 1977 hasta 1979 ocurrieron distintos cambios en el lenguaje, y durante este tiempo se publicó un libro que sirve como manual para el lenguaje, titulado "The C Programming Language", publicado en 1978 por Ritchie y Brian W. Kernighan. Cinco años después, se estandarizó C en el American National Standards Institute, y desde ese momento, al lenguaje se le refiere como ANSI Standard C. De C salieron varios lenguajes derivados, tales como Objective C y C++. Además, también surgió Java, el cual se creó como un lenguaje que simplifica C.\cite{mritchie_1993_the}\\

Continuando con los recursos utilizados en este proyecto, se utilizó la librería pthread. Esta es una librería de POSIX la cual es un estándar para el uso de hilos (threads), en C y C++, los cuales permiten un flujo de procesos de manera concurrente. El uso de estos hilos es más efectivo en procesadores con múltiples núcleos, ya que se pueden asignar los procesos a distintos núcleos, haciendo la ejecución más rápido.\cite{ippolito_2020_linux}\\

Luego, un recurso escencial para la solución del proyecto es el algoritmo de Huffman. 

Además, se escogió CLion como el IDE preferido para este proyecto. Este IDE es de la empresa JetBrains y fue lanzado al mercado en 2014\cite{avram_2014_jetbrains} con herramientas que ayudan a la creación de código, tales como refactoring, generación de código para sets/gets, terminación de código y arreglos rápidos del código escrito.\cite{jetbrains_intelligent}\\

Finalmente, ya que se mencionó tanto POSIX como UNIX se va a brindar información sobre estos. Portable Operating System Interface for UNIX, o POSIX, son estándares establecidos por la IEEE y publicados por la ANSI e ISO (International Organization for Standardization), estos estándares permiten el desarrollo de código universal, para que pueda correr en todos los sistemas operativos que implementen POSIX, tales como macOS o Ubuntu, la mayoría de los sistemas basados en UNIX cumplen con POSIX.\cite{universityinformationtechnologyservices_2021_about} UNIX es un sistema operativo que fue creado para brindar a programadores funciones simples pero potentes, y que permitiera el uso de múltiples usuarios y de multi tarea, este se compone de tres partes, el kernel, los archivos de configuración de sistema y los programas.\cite{idahostateuniversity_1997_what}

\section{Descripción de la solución}
El primer paso de la solución fue crear las distintas variables y definiciones para el programa. Primero se crea un MUTEX que se va a utilizar para el arreglo de repeticiones de bits, el cual tiene 256 posiciones.\cite{cppdev_2010_c} \cite{manrow_2011_c} Además, existen dos arreglos, uno llamado solution\_array que tiene 256 posiciones, las cuales representan los 256 bytes existentes, aquí se almacena la cantidad de repeticiones de un byte dado por la posición del arreglo, y el otro, llamado solution\_aux, tiene la misma cantidad de espacios y se utiliza como un auxiliar que va a contener en sus posiciones el número del byte, es decir en la posición 0 se coloca el número 0, para que cuando se ordene el arreglo principal, este se ordena al mismo tiempo y así se pueda identificar el byte con su repetición correspondiente. Luego, se crean cuatro variables, la primera llamada readers\_num se utiliza para definir la cantidad de hilos lectores por parte del usuario, la segunda, filepath, se utiliza como puntero a la dirección donde se encuentra el archivo a comprimir, la tercera es filelen que indica el tamaño de dicho archivo, y por último está filename que se usa para darle nombre al archivo comprimido.\\

Se realiza un radix sort para poder ordenar los resultados de mayor a menor repeticiones por cada byte, este sort realiza una llamada al metodo count\_sort el cual se encarga de \textbf{TERMINAR DE EXPLICAR SORTS}.\\

Se crea el método reading\_file() el cual es el que los hilos productores se encargan de ejecutar. Este va a abrir el archivo indicado en la dirección dada en la ejecución del programa.\cite{chanilastnam_2015_c} \cite{cppreferencecom_2021_fread} \cite{kerrisk_2010_fseek3} Por mientras que no se haya llegado al final del archivo, se realiza un bloqueo del mutex para el buffer de lectura de los productores, para que ningún otro hilo productor toque este buffer, si el hilo que bloqueó este mutex se encuentra al final del documento, entonces se va a marcar el flag indicando que se llegó al final del archivo, se desbloquea para asegurarse que ningún otro hilo se quede pegado dentro de un wait condition, si no, se continua con la lectura del byte del archivo, si la posición siguiente del productor es igual que la posición del consumidor entonces se llama un wait condition, utilizando la condición de consumo y el mutex del buffer, esto para detener a los productores hasta que se consuma, si esto no ocurre se sigue normal, se aumenta el indicador de posición de productores, si se llega al fin del documento se desbloquea el mutex del buffer y se indica que se terminó con la señal de condición de read condition con un broadcast, se cierra la lectura del archivo, se marca el flag en 0 indicando que se llegó al final del archivo,  y por último se destruyen los hilos productores.\cite{kerrisk_2010_pthread_exit3} \\

Luego, se crea el método adding\_to\_array(), el cual es el proceso de los consumidores. Este por mientras que la variable filelen sea 1 se ejecuta toda su lógica, si no se eliminan los threads consumidores. Si esta variable es true entonces se empieza el trabajo de los consumidores, primero se bloquea el mutex del array de la solución, si filelen es 0 entonces se desbloquea el array y se eliminan los consumidores, si no se continua. Además, existe un while donde si la posición de los consumidores es igual o mayor a la posición de los productores y el flag de final de archivo está en true entonces los consumidores esperan a que los productores generen más bytes para leer y estos indiquen cuando terminen, y también hay un if que verifica si el indicador filelen es falso entonces se desbloquea el mutex del array de solución y se eliminan los threads consumidores. Finalmente, si no se cumple ninguna de las condiciones anteriores entonces, como cada posición del array indica el byte correspondiente, se aumenta en 1 la posicion i para indicar la cantidad de repeticiones por cada byte i, esta posición se modifica leyendo cada posición del buffer, ya que este almacena el byte leido, tomando como índice el restante de la división de la posición de los consumidores entre el BUFFERLEN, se aumenta el índice de posición de los consumidores, se disminuye filelen y por último se desbloquea el mutex de la solución, se envía la señal que se terminó de consumir por medio de un broadcast y se eliminan los consumidores.\\

Para terminar, dentro del main primero creamos un array auxiliar para la solución, donde se ordenan los bytes de mayor a menor repetición del array original de solución. Luego se realizan verificaciones para revisar si se da el número de hilos productores o consumidores deseados o la dirección del archivo a leer. Luego se abre el documento para probar si se logra abrir correctamente, si no se termina la ejecución del programa, y luego se recorre todo el archivo para encontrar su tamaño, se devuelve el puntero que controla lectura y se cierra. Luego se hace la creación de productores con su asignación de la tarea del método reading file, si falla se detiene el programa, al igual con los consumidores con su método adding to array, si falla también se detiene. Por último, se hace join al hilo principal del programa a los productores y consumidores, si falla se detiene el programa.\cite{kerrisk_2010_pthread_join3} Seguidamente, se ejecuta el mergesort para ordenar el solution array dentro del solution aux declarado al principio del main, y luego imprimiendo el resultado de las repeticiones, usando ambos arrays de solución, uno para indicar el byte y otro para indicar sus repeticiones, y finalmente se destruyen los mutex y las condiciones.\\

\section{Resultados de pruebas}
Para las pruebas se utilizó un equipo con un procesador Intel Core i7-8550U, el cual corre a una velocidad base de 1,8 GHz y un turbo hasta 4,00 GHz, con 4 cores y 8 threads, y cuenta con 8 GB de RAM.\\

Estas pruebas se realizaron con 7 archivos de distintos tamaños y tipos, dos archivos txt, dos PDF, una foto de 24.5 megapíxeles y por último dos videos, uno 4K HDR y otro en 8K. Además, por cada archivo se realizaron cuatro casos de prueba, un hilo para productor y consumidor, 10 productores 1 consumidor, 10 consumidores 1 productor, y 5 productores 8 consumidores.\\

La primera prueba realizada fue la lectura del txt más pequeño de 33 bytes. Este se leyó con el programa en los siguientes tiempos 0.002s, 0.003s, 0.002s, y 0.003s para cada caso correspondiente, aquí se puede notar que al ser un archivo sumamente pequeño no hay mucha diferencia de tiempo entre cada caso.
Seguidamente, se realiza la lectura de otro archivo txt de 7.4 kB, los tiempos respectivos de cada prueba fueron 0.011s, 0.018s, 0.129s, y 0.062s. Se logra percibir una diferencia en el caso donde existen 10 consumidores y 1 productor que tardo mas tiempo que el resto de las pruebas, seguido del caso de 5 productores 8 consumidores.\\

Luego se usó un PDF de 152.7 kB. Sus tiempos por cada caso fueron 0.193s, 0.276s, 2.371s, y 1.191s. Aquí ya se puede observar un patrón donde el caso de igual cantidad de productores y consumidores es el mejor y el peor es más consumidores que productores.\\

Se continua con la lectura de otro PDF de 4.2 MB. Sus tiempos respectivos fueron 5.253s, 16.084s, 2m 48.18s, y 1m 14.46s. Se confirma la observación realizada en las pruebas anteriores, siendo el mejor caso la cantidad igual de productores y consumidores que produjo el menor tiempo.\\

A continuación, se realizó la prueba con la fotografía con un tamaño de 7.6 MB, dando los siguientes tiempos 12.317s, 32.694s, 5m 4.31s, y 2m 18.13s. Confirmando una vez más que el mejor tiempo se realizó con la misma cantidad de productores y consumidores, siendo el peor cuando hay 10 consumidores y 1 productor.\\

Por último, ya que el equipo ha demostrado durar bastante tiempo en correr los archivos más pesados de las pruebas anteriores, y, además, se logró confirmar que el mejor caso es cuando existe la misma cantidad de productores y consumidores, ambos videos se van a correr usando este caso para dar una idea del tiempo que podría durar en los peores casos. El tamaño es 437.8 MB para el video 4K HDR y 936,6 MB para el video 8K. El video 4K HDR se leyó en un tiempo de 17m 01.58s y el 8K con un tiempo de 38m 19.41s, si el promedio de diferencia entre el mejor y peor caso es un aumento del tiempo de 30 veces, entonces se podría aproximar que el peor caso para cada video duraría 8 horas para el video en 4K y 16 horas para el video en 8K.\\

\section{Conclusiones}
Se puede concluir que, por medio de los resultados anteriores, lo mejor es manejar la misma cantidad de hilos productores y consumidores, ya que cualquier espera que pueda ocurrir por cualquiera de los hilos se reduce a casi cero, por que conforme los productores colocan bytes en el buffer, los consumidores los procesan, y, como se pudo observar en el peor caso, cuando hay más consumidores que productores, estos se quedan esperando por bytes para consumir ya que al ser mayor la cantidad de consumidores, el procesamiento de estos se hace mucho más rápido que la colocación de bytes en el buffer por parte de los productores y esto genera varias esperas de los consumidores para poder hacer su trabajo.\\

Además, también se pudo observar que el manejo de hilos en un proyecto ayuda a que las tareas sean ejecutadas con mayor rapidez que si se manejara un único hilo principal, ya que a estos hilos se les asignan tareas para que sean ejecutadas en paralelo o de manera concurrente.\cite{portfoliocourses_2022_introduction} \\

Finalmente, los resultados anteriores se podrían mejorar haciendo uso de hardware más potente y moderno, principalmente utilizando un procesador con mayor cantidad de cores y threads, ya que este recurso sería mucho más rápido en el manejo de hilos paralelos y de ejecución de sus tareas.\\

\section{Aprendizajes}
En esta sección se muestran los aprendizajes de cada integrante del grupo de trabajo.\\

Jorge Durán Campos: Aprendí que usando toda la capacidad de procesamiento de un multiprocesador actual se pueden realizar procesos de manera más rápida haciendo uso de hilos, debido a que estos amortiguan la carga de un proceso entre los diferentes núcleos, y de esta forma conseguir una disminución de tiempo de ejecución proporcional a la cantidad de núcleos utilizados para este fin. También me ayudó a complementar, junto con la teoría, la importancia de la sincronización entre hilos.\\

Luis Antonio Montes de Oca Ruiz: De este proyecto aprendí sobre el manejo de hilos y como estos ayudan a mejorar la ejecución de un programa, dividiendo las tareas en cada hilo y así mejorando el tiempo de ejecución y el uso de recursos compartidos. También el manejo de exclusiones MUTEX que permiten un manejo correcto de la región crítica y recurso compartido entre los distintos hilos, siendo esto una parte sumamente importante de este tipo de ejecución, ya que ocurren errores importantes si no se maneja de manera correcta, como la perdida de datos o ciclos de espera de un hilo por otro.\\

Diego Quirós Artiñano: Aprendí como implementar la teoría que vimos en clase. El proyecto me ayudó a entender en mayor detalle cómo es que los hilos corren durante su ejecución. Por ejemplo, a pesar de que son paralelos en teoría, en la práctica por la exclusión mutua entre los hilos el programa ejecuta de manera secuencial. Comprendí la importancia de los semáforos y la exclusión mutua. Además, entendí el uso de la función de cond\_wait(), y la diferencia entre el cond\_signal() y cond\_broadcast().\\

\newpage
\onecolumn
\bibliographystyle{ieeetr} 
\bibliography{ref.bib}

\end{document}
